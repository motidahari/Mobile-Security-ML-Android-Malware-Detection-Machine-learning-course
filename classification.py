from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score
from sklearn.svm import LinearSVC
from plt import plotting
import warnings
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import GradientBoostingClassifier
warnings.simplefilter(action='ignore', category=FutureWarning)


def train_modelGradientBoostingClassifier(X_train, y_train, n_estimators, learning_rate, random_state_val):
    """
        This function trains a Gradient Boosting classifier model on the input training data.

    Inputs:
        X_train (numpy.ndarray): The feature values for the training data.
        y_train (numpy.ndarray): The labels for the training data.
        n_estimators (int): The number of decision trees in the ensemble.
        learning_rate (float): The learning rate of the algorithm.
        random_state_val (int): The seed used by the random number generator.

    Returns:
        model (sklearn.ensemble.GradientBoostingClassifier): The trained Gradient Boosting model.
    """

    # Initialize the model
    model = GradientBoostingClassifier(
        n_estimators=n_estimators, learning_rate=learning_rate, random_state=random_state_val)
    model.fit(X_train, y_train)
    return model


def train_modelDecisionTreeClassifier(X_train, y_train, max_depth, random_state_val):
    """
        This function trains a Decision Tree classifier model on the input training data.

    Inputs:
        X_train (numpy.ndarray): The feature values for the training data.
        y_train (numpy.ndarray): The labels for the training data.
        max_depth (int): The maximum depth of the tree.
        random_state_val (int): The seed used by the random number generator.

    Returns:
        model (sklearn.tree.DecisionTreeClassifier): The trained Decision Tree model.
    """

    # Initialize the model
    model = DecisionTreeClassifier(
        max_depth=max_depth, random_state=random_state_val)
    model.fit(X_train, y_train)
    return model


def train_modelKNeighborsClassifier(X_train, y_train, n_neighbors):
    """
        This function trains a KNN classifier model on the input training data.

    Inputs:
        X_train (numpy.ndarray): The feature values for the training data.
        y_train (numpy.ndarray): The labels for the training data.
        n_neighbors (int): The number of nearest neighbors used for the classification.

    Returns:
        model (sklearn.neighbors.KNeighborsClassifier): The trained KNN model.
    """

    # Initialize the model
    model = KNeighborsClassifier(n_neighbors=n_neighbors)
    model.fit(X_train, y_train)
    return model


def train_modelLogisticRegression(X_train, y_train, C, epsilon, random_state_val):
    """
        This function trains a Sec-SVM classifier model on the input training data.

    Inputs:
        X_train (numpy.ndarray): The feature values for the training data.
        y_train (numpy.ndarray): The labels for the training data.
        C (float): The regularization parameter.
        epsilon (float): A small constant used to determine when to stop the training.

    Returns:
        model (sklearn.linear_model.LogisticRegression): The trained Sec-SVM model.
    """

    # Initialize the model
    model = LogisticRegression(
        C=C, penalty='l2', random_state=random_state_val, tol=epsilon)
    model.fit(X_train, y_train)
    return model


def train_modelLinearSVC(X_train, y_train, C, epsilon, random_state_val):
    """
        This function trains a Sec-SVM classifier model on the input training data.

    Inputs:
        X_train (numpy.ndarray): The feature values for the training data.
        y_train (numpy.ndarray): The labels for the training data.
        C (float): The regularization parameter.
        epsilon (float): A small constant used to determine when to stop the training.

    Returns:
        model (sklearn.svm.LinearSVC): The trained Sec-SVM model.
    """

    # Initialize the model
    model = LinearSVC(C=C, random_state=random_state_val, tol=epsilon)
    model.fit(X_train, y_train)
    return model


def evaluate_model(model, X_test, y_test):
    """
    This function evaluates a model on the test data.

    Inputs:
        model (sklearn.svm.LinearSVC): The trained model.
        X_test (numpy.ndarray): The feature values for the test data.
        y_test (numpy.ndarray): The labels for the test data.

    Returns:
        accuracy (float): The accuracy score of the model.
        precision (float): The precision score of the model.
        recall (float): The recall score of the model.
    """
    # Predict the labels on the test data using the model
    # y_pred = model.predict(X_test)
    threshold = 0.5
    y_pred = model.predict(X_test)
    # y_pred[y_pred >= threshold] = 1
    # y_pred[y_pred < threshold] = 0
    # Compute the accuracy, precision, and recall scores
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    # plotting(y_pred[:100], y_test[:100])

    return accuracy, precision, recall


def classify_apk(model, apk_features):
    """
        This function makes a prediction for a new APK by using the trained model to classify the APK based on its features.

    Inputs:
        model (sklearn.svm.LinearSVC): The trained model.
        apk_features (numpy.ndarray): The feature values for the new APK.

    Returns:
        label (int): The predicted label for the new APK.
    """
    return model.predict(apk_features)
